{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6ab677",
   "metadata": {},
   "source": [
    "# Deep Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b4220",
   "metadata": {},
   "source": [
    "### José Pablo Kiesling Lange - 21581"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6091d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4567488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fec6783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d6bf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 327\n",
    "rng = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee1c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ffdf5",
   "metadata": {},
   "source": [
    "El entorno de CartPole-v1 tiene un espacio de acciones discreto:\n",
    "\n",
    "| Acción | Descripción                       |\n",
    "|--------|-----------------------------------|\n",
    "| 0      | Mover el carro a la izquierda     |\n",
    "| 1      | Mover el carro a la derecha       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de130955",
   "metadata": {},
   "source": [
    "Y el espacio de estados es continuo, con los siguientes valores:\n",
    "\n",
    "| Estado        | Descripción                       | Mínimo | Máximo |\n",
    "|---------------|-----------------------------------|--------|--------|\n",
    "| Cart Position | Posición del carro                | -4.8   | 4.8    |\n",
    "| Cart Velocity | Velocidad del carro               | -Inf   | Inf    |\n",
    "| Pole Angle    | Ángulo del poste                 | -24°   | 24°    |\n",
    "| Pole Velocity | Velocidad angular del poste       | -Inf   | Inf    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5ba8a2",
   "metadata": {},
   "source": [
    "## Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9dde5a",
   "metadata": {},
   "source": [
    "Dado que la entrada de la red será el estado, tendrá 4 nodos de entrada. La salida será la acción a tomar, por lo que tendrá 2 nodos de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6830a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(Model):\n",
    "    def __init__(self, input_dim=4, output_dim=2, lr=0.0001):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "\n",
    "        self.hidden1 = Dense(128, activation='relu')\n",
    "        self.hidden2 = Dense(128, activation='relu')\n",
    "        self.out = Dense(self.output_dim, activation='linear')\n",
    "        \n",
    "        self.optimizer = Adam(learning_rate=self.lr)\n",
    "        self.loss_fn = MeanSquaredError()\n",
    "\n",
    "        self.build((None, self.input_dim))\n",
    "        \n",
    "    def call(self, state):\n",
    "        x = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        \n",
    "        if tf.rank(x) == 1:\n",
    "            x = tf.expand_dims(x, 0)\n",
    "        \n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        q_values = self.out(x)\n",
    "        return q_values\n",
    "    \n",
    "    def predict(self, state):\n",
    "        q_values = self(state)\n",
    "        return q_values.numpy()[0]\n",
    "    \n",
    "    def predict_batch(self, states):\n",
    "        q_values = self(states)\n",
    "        return q_values.numpy()\n",
    "    \n",
    "    def hard_update(self, target_network):\n",
    "        self.set_weights(target_network.get_weights())\n",
    "        \n",
    "    def soft_update(self, target_network, tau=0.1):\n",
    "        target_weights = self.get_weights()\n",
    "        source_weights = target_network.get_weights()\n",
    "        new_weights = []\n",
    "        for target_w, source_w in zip(target_weights, source_weights):\n",
    "            new_w = tau * source_w + (1 - tau) * target_w\n",
    "            new_weights.append(new_w)\n",
    "        self.set_weights(new_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowpy310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
